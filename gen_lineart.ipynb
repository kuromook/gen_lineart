{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81919ba8-7f25-42b0-a3cb-deff87dd218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms.functional as TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e17f9d-aa8f-4936-81e9-c08807f40e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.5593\n",
      "Epoch 2: Loss = 0.4000\n",
      "Epoch 3: Loss = 0.3104\n",
      "Epoch 4: Loss = 0.2488\n",
      "Epoch 5: Loss = 0.2197\n",
      "Epoch 6: Loss = 0.1808\n",
      "Epoch 7: Loss = 0.1523\n",
      "Epoch 8: Loss = 0.1383\n",
      "Epoch 9: Loss = 0.1259\n",
      "Epoch 10: Loss = 0.1006\n",
      "Epoch 11: Loss = 0.0942\n",
      "Epoch 12: Loss = 0.0862\n",
      "Epoch 13: Loss = 0.0861\n",
      "Epoch 14: Loss = 0.0924\n",
      "Epoch 15: Loss = 0.0738\n",
      "Epoch 16: Loss = 0.0961\n",
      "Epoch 17: Loss = 0.0584\n",
      "Epoch 18: Loss = 0.0483\n",
      "Epoch 19: Loss = 0.0654\n",
      "Epoch 20: Loss = 0.0456\n",
      "Epoch 21: Loss = 0.0490\n",
      "Epoch 22: Loss = 0.0424\n",
      "Epoch 23: Loss = 0.0573\n",
      "Epoch 24: Loss = 0.0427\n",
      "Epoch 25: Loss = 0.0422\n",
      "Epoch 26: Loss = 0.0290\n",
      "Epoch 27: Loss = 0.0208\n",
      "Epoch 28: Loss = 0.0344\n",
      "Epoch 29: Loss = 0.0492\n",
      "Epoch 30: Loss = 0.0309\n",
      "Epoch 31: Loss = 0.0303\n",
      "Epoch 32: Loss = 0.0315\n",
      "Epoch 33: Loss = 0.0380\n",
      "Epoch 34: Loss = 0.0304\n",
      "Epoch 35: Loss = 0.0297\n",
      "Epoch 36: Loss = 0.0294\n",
      "Epoch 37: Loss = 0.0227\n",
      "Epoch 38: Loss = 0.0285\n",
      "Epoch 39: Loss = 0.0257\n",
      "Epoch 40: Loss = 0.0213\n",
      "Epoch 41: Loss = 0.0193\n",
      "Epoch 42: Loss = 0.0285\n",
      "Epoch 43: Loss = 0.0283\n",
      "Epoch 44: Loss = 0.0239\n",
      "Epoch 45: Loss = 0.0262\n",
      "Epoch 46: Loss = 0.0219\n",
      "Epoch 47: Loss = 0.0238\n",
      "Epoch 48: Loss = 0.0235\n",
      "Epoch 49: Loss = 0.0232\n",
      "Epoch 50: Loss = 0.0210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================\n",
    "#  U-Net Generator\n",
    "# ========================\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.down1 = self.conv_block(in_channels, 64)   # 256 -> 128\n",
    "        self.down2 = self.conv_block(64, 128)           # 128 -> 64\n",
    "        self.down3 = self.conv_block(128, 256)          # 64 -> 32\n",
    "        self.down4 = self.conv_block(256, 512)          # 32 -> 16\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = self.up_block(512, 256)              # 16 -> 32\n",
    "        self.up2 = self.up_block(512, 128)              # 32 -> 64\n",
    "        self.up3 = self.up_block(256, 64)               # 64 -> 128\n",
    "        self.up4 = self.up_block(128, 64)               # 128 -> 256 ←★追加\n",
    "\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 4, 2, 1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def up_block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_c, out_c, 4, 2, 1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "\n",
    "        u1 = self.up1(d4)\n",
    "        u2 = self.up2(torch.cat([u1, d3], dim=1))\n",
    "        u3 = self.up3(torch.cat([u2, d2], dim=1))\n",
    "        u4 = self.up4(torch.cat([u3, d1], dim=1))\n",
    "        out = self.final(u4)\n",
    "\n",
    "        return torch.tanh(out)\n",
    "\n",
    "\n",
    "\n",
    "# ========================\n",
    "#  データセット定義\n",
    "# ========================\n",
    "class SketchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, rough_dir, line_dir, transform=None):\n",
    "        self.rough_files = sorted(os.listdir(rough_dir))\n",
    "        self.line_files = sorted(os.listdir(line_dir))\n",
    "        self.rough_dir = rough_dir\n",
    "        self.line_dir = line_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rough_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rough = Image.open(os.path.join(self.rough_dir, self.rough_files[idx])).convert(\"RGB\")\n",
    "        line = Image.open(os.path.join(self.line_dir, self.line_files[idx])).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            rough = self.transform(rough)\n",
    "            line = self.transform(line)\n",
    "        return rough, line\n",
    "\n",
    "# ========================\n",
    "#  学習設定\n",
    "# ========================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = SketchDataset(\n",
    "    \"dataset/train/rough\",\n",
    "    \"dataset/train/line\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "generator = UNetGenerator().to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "# ========================\n",
    "#  学習ループ\n",
    "# ========================\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(50):\n",
    "        for rough, line in train_loader:\n",
    "            rough, line = rough.to(device), line.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = generator(rough)\n",
    "            loss = criterion(output, line)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
    "        torch.save(generator.state_dict(), f\"checkpoints/unet_epoch{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d253691-7a41-4905-b39e-14f7f5de0816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 推論完了: results/result_line.png に保存しました\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================\n",
    "# 推論設定\n",
    "# ========================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# モデルロード\n",
    "generator = UNetGenerator().to(device)\n",
    "checkpoint_path = \"checkpoints/unet_epoch50.pth\"  # 最新の学習済みモデルを指定\n",
    "assert os.path.exists(checkpoint_path), f\"{checkpoint_path} が見つかりません\"\n",
    "generator.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "generator.eval()\n",
    "\n",
    "# ========================\n",
    "# 推論実行\n",
    "# ========================\n",
    "img = Image.open(\"test/rough/sample.jpg\").convert(\"RGB\")\n",
    "img = TF.resize(img, (128, 128))  # trainer と同じサイズに揃える\n",
    "img = TF.to_tensor(img).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = generator(img)\n",
    "\n",
    "# 出力画像を保存\n",
    "output_img = TF.to_pil_image((output.squeeze(0) * 0.5 + 0.5).clamp(0, 1).cpu())\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "output_img.save(\"results/result_line.png\")\n",
    "\n",
    "print(\"✅ 推論完了: results/result_line.png に保存しました\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890dab9-fb7f-497d-a3a0-4ff0551fac16",
   "metadata": {},
   "source": [
    "result\n",
    "\n",
    "![result](./results/result_line.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2721061-310d-4cb1-ab55-c83b623e9196",
   "metadata": {},
   "source": [
    "sample  \n",
    "![sample](./test/rough/sample.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091a4a7-931d-49c7-8818-a96e615d5396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
