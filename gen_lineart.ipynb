{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cc2380-7f15-4f5c-878d-d5a1a6fe33a5",
   "metadata": {},
   "source": [
    "checklist  \n",
    "+ [x] plan1 OK\n",
    "+ [x] plan2 OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cbc19-c4b5-4e5c-be15-457ace0ca179",
   "metadata": {},
   "source": [
    "ç·šãŒå¤ªãå‡ºã™ãã¦ã„ã‚‹å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒç·šã‚’**éåº¦ã«å¤ªãäºˆæ¸¬ã™ã‚‹ã“ã¨ã¸ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’å¼·åŒ–**ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€ä¸»ã«**æå¤±é–¢æ•°**ã¨**ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®è¡¨ç¾**ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§æ”¹å–„ã§ãã¾ã™ã€‚\n",
    "\n",
    "ä»¥ä¸‹ã®2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è©¦ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã‚‰ã¯ç‹¬ç«‹ã—ãŸèª¿æ•´ãªã®ã§ã€ä¸€ã¤ãšã¤è©¦ã™ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n",
    "\n",
    "-----\n",
    "\n",
    "## 1\\. ğŸ¯ ãƒã‚¸ãƒ†ã‚£ãƒ–é‡ã¿ (`pos_weight`) ã®å¾®èª¿æ•´\n",
    "\n",
    "ç·šãŒå¤ªããªã‚‹æœ€å¤§ã®åŸå› ã¯ã€ç·šç”»ãƒ”ã‚¯ã‚»ãƒ«ã«èª²ã—ã¦ã„ã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆ`pos_weight`ï¼‰ãŒé«˜ã™ãã‚‹ãŸã‚ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã€Œç·šãŒã‚ã‚‹ã€ã¨äºˆæ¸¬ã™ã‚‹ã“ã¨ã§é«˜ã„å ±é…¬ã‚’å¾—ã‚ˆã†ã¨ã—ã€çµæœã¨ã—ã¦ç·šã‚’å¤ªãåºƒã’ã‚ˆã†ã¨ã—ã¾ã™ã€‚\n",
    "\n",
    "### âœ… ä¿®æ­£æ¡ˆï¼š`pos_weight` ã®å€¤ã‚’ã•ã‚‰ã«ä¸‹ã’ã‚‹\n",
    "\n",
    "ç¾åœ¨æ¡ç”¨ã—ã¦ã„ã‚‹å€¤ï¼ˆä¾‹: $5.0$ï¼‰ã‹ã‚‰ã€ã•ã‚‰ã«ä¸‹ã’ã¦å†å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "  * **ç¾åœ¨ã®è¨­å®šï¼ˆä¾‹ï¼‰:** `pos_weight_tensor = torch.tensor(5.0).to(device)`\n",
    "  * **ä¿®æ­£æ¡ˆ:** **`3.0`** ã‚„ **`2.0`** ç¨‹åº¦ã«å€¤ã‚’ä¸‹ã’ã¦è©¦ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "pos_weight_value = 3.0 # ä¾‹: 5.0 ã‹ã‚‰ 3.0 ã¸å¤‰æ›´\n",
    "pos_weight_tensor = torch.tensor(pos_weight_value, dtype=torch.float).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "```\n",
    "\n",
    "ã“ã®å€¤ã‚’ä¸‹ã’ã‚‹ã“ã¨ã§ã€ç·šã®**æ¿ƒã•**ã¨**å¤ªã•**ã®ä¸¡æ–¹ãŒæŠ‘åˆ¶ã•ã‚Œã€èƒŒæ™¯ã¨ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãŒå’Œã‚‰ãã¾ã™ã€‚\n",
    "\n",
    "-----\n",
    "\n",
    "## 2\\. ğŸ“ L1æå¤±ã®å°å…¥ (ç·šã®ç´°ã•ã®å¼·åˆ¶)\n",
    "\n",
    "`BCEWithLogitsLoss`ã¯ãƒ”ã‚¯ã‚»ãƒ«ã”ã¨ã®åˆ†é¡èª¤å·®ï¼ˆç·šã‹èƒŒæ™¯ã‹ï¼‰ã‚’æ¸¬ã‚Šã¾ã™ãŒã€ç·šã®**ç´°ã•**ã‚„**å¹³å‡çš„ãªæ¿ƒã•**ã‚’åˆ¶å¾¡ã™ã‚‹ã«ã¯é™ç•ŒãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "å‡ºåŠ›ã•ã‚ŒãŸç·šç”» (`torch.sigmoid(pred)`) ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ (`line`) ã®é–“ã®**L1æå¤±**ï¼ˆçµ¶å¯¾èª¤å·®ï¼‰ã‚’ãƒ¡ã‚¤ãƒ³æå¤±ã«è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã«ãƒ”ã‚¯ã‚»ãƒ«å€¤ã®èª¤å·®ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ã‚ˆã†å¼·åˆ¶ã—ã€éåº¦ã«æ˜ã‚‹ãï¼ˆç·šãŒå¤ªãï¼‰ãªã‚‹ã®ã‚’é˜²ãã¾ã™ã€‚\n",
    "\n",
    "### âœ… ä¿®æ­£æ¡ˆï¼šãƒ¡ã‚¤ãƒ³æå¤±ã«L1æå¤±ã‚’ãƒŸãƒƒã‚¯ã‚¹ã™ã‚‹\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§ã€`BCEWithLogitsLoss`ã¨`L1Loss`ã‚’çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "```python\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—å†…\n",
    "for rough, line in loader:\n",
    "    # ... (å‰å‡¦ç†ã¯ãã®ã¾ã¾) ...\n",
    "    \n",
    "    pred = model(rough)\n",
    "    \n",
    "    # 1. ãƒ¡ã‚¤ãƒ³æå¤± (BCE with pos_weight)\n",
    "    loss_main_bce = criterion(pred, line)\n",
    "    \n",
    "    # 2. L1æå¤± (Sigmoidå¾Œã®å‡ºåŠ›ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®çµ¶å¯¾èª¤å·®)\n",
    "    # L1æå¤±ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ãƒ”ã‚¯ã‚»ãƒ«å€¤ãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«è¿‘ã¥ãã‚ˆã†ã«å¼·åˆ¶ã™ã‚‹ã€‚\n",
    "    loss_main_l1 = F.l1_loss(torch.sigmoid(pred), line) \n",
    "    \n",
    "    # 3. ãƒ¡ã‚¤ãƒ³æå¤±ã®çµ„ã¿åˆã‚ã›ã¨ã‚¨ãƒƒã‚¸æå¤±\n",
    "    # BCEã¨L1ã‚’ãƒŸãƒƒã‚¯ã‚¹ (ä¾‹: 80% BCE, 20% L1)\n",
    "    loss_main = 0.8 * loss_main_bce + 0.2 * loss_main_l1 \n",
    "    \n",
    "    loss_edge = edge_loss(torch.sigmoid(pred), line) \n",
    "\n",
    "    # ç·æå¤± (L1æå¤±ãŒå¤ªã•ã‚’æŠ‘åˆ¶ã™ã‚‹åŠ©ã‘ã«ãªã‚‹ãŸã‚ã€ã‚¨ãƒƒã‚¸é‡ã¿ã¯ 1.0 ã§ç¶­æŒã—ã¦ã‚‚ã‚ˆã„)\n",
    "    loss = loss_main + 1.0 * loss_edge \n",
    "    \n",
    "    # ... (backward ä»¥é™ã¯ãã®ã¾ã¾) ...\n",
    "```\n",
    "\n",
    "ã“ã“ã§ã€`L1Loss`ã®é‡ã¿ï¼ˆä¾‹: $0.2$ï¼‰ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ç·šã®å¤ªã•ã«å¯¾ã™ã‚‹æŠ‘åˆ¶åŠ›ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚\n",
    "\n",
    "**æ¨å¥¨æ‰‹é †ã¨ã—ã¦ã¯ã€ã¾ãš `pos_weight` ã®å€¤ã‚’ä¸‹ã’ã¦å†å­¦ç¿’ã—ã€åŠ¹æœãŒä¸ååˆ†ã§ã‚ã‚Œã° L1 æå¤±ã®å°å…¥ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81919ba8-7f25-42b0-a3cb-deff87dd218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-11-17 03:19:15.056644560 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# train_unet_res_dilated.py\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890416e1-e619-4a91-a430-c77f2a6e922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Residual Block\n",
    "# -----------------------\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        self.in1 = nn.InstanceNorm2d(ch)\n",
    "        self.conv2 = nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        self.in2 = nn.InstanceNorm2d(ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.in1(self.conv1(x)))\n",
    "        h = self.in2(self.conv2(h))\n",
    "        return x + h\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Dilated Conv Block\n",
    "# -----------------------\n",
    "class DilatedConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, dilation=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 3, dilation=dilation, padding=dilation)\n",
    "        self.inorm = nn.InstanceNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.inorm(self.conv(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e17f9d-aa8f-4936-81e9-c08807f40e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# U-Net Generator (1ch Input / 1ch Output)\n",
    "# -----------------------\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 3, padding=1), \n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            ResBlock(64)\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            ResBlock(128)\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc3 = nn.Sequential(\n",
    "            DilatedConvBlock(128, 256, dilation=2),\n",
    "            ResBlock(256)\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "        DilatedConvBlock(256, 512, dilation=4), \n",
    "        ResBlock(512),\n",
    "        DilatedConvBlock(512, 512, dilation=4), \n",
    "        )\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec3 = nn.Sequential(\n",
    "        nn.Conv2d(512, 256, 3, padding=1),\n",
    "        nn.InstanceNorm2d(256),\n",
    "        nn.ReLU(True),\n",
    "        ResBlock(256)\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            ResBlock(128)\n",
    "        )\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            DilatedConvBlock(128, 64, dilation=1),\n",
    "            ResBlock(64)\n",
    "        )\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        u3 = self.up3(b)\n",
    "        d3 = self.dec3(torch.cat([u3, e3], dim=1))\n",
    "\n",
    "        u2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([u2, e2], dim=1))\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([u1, e1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3bd368-3188-449e-877f-36f1198e03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_edges(x):\n",
    "    sobel_x = torch.tensor([[-1,0,1],[-2,0,2],[-1,0,1]],\n",
    "                           dtype=torch.float32, device=x.device).view(1,1,3,3)\n",
    "    sobel_y = torch.tensor([[-1,-2,-1],[0,0,0],[1,2,1]],\n",
    "                           dtype=torch.float32, device=x.device).view(1,1,3,3)\n",
    "\n",
    "    g_x = F.conv2d(x, sobel_x, padding=1)\n",
    "    g_y = F.conv2d(x, sobel_y, padding=1)\n",
    "\n",
    "    return torch.sqrt(g_x**2 + g_y**2 + 1e-6)\n",
    "    \n",
    "def edge_loss(pred, target):\n",
    "    return F.l1_loss(sobel_edges(pred), sobel_edges(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a609f6b2-53ba-411a-aaaa-58f37eafac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class SketchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, rough_dir, line_dir, transform=None):\n",
    "        self.rough_files = sorted(os.listdir(rough_dir))\n",
    "        self.line_files = sorted(os.listdir(line_dir))\n",
    "        self.rough_dir = rough_dir\n",
    "        self.line_dir = line_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rough_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rough = Image.open(os.path.join(self.rough_dir, self.rough_files[idx])).convert(\"L\")\n",
    "        line  = Image.open(os.path.join(self.line_dir,  self.line_files[idx])).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            rough = self.transform(rough)\n",
    "            line  = self.transform(line)\n",
    "\n",
    "        return rough, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe99c1f0-501d-47c6-b0d1-c1ade8135268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_loss=0.7899\n",
      "Epoch 2: avg_loss=0.6730\n",
      "Epoch 3: avg_loss=0.6409\n",
      "Epoch 4: avg_loss=0.6223\n",
      "Epoch 5: avg_loss=0.6099\n",
      "Epoch 6: avg_loss=0.6017\n",
      "Epoch 7: avg_loss=0.5959\n",
      "Epoch 8: avg_loss=0.5918\n",
      "Epoch 9: avg_loss=0.5862\n",
      "Epoch 10: avg_loss=0.5841\n",
      "Epoch 11: avg_loss=0.5804\n",
      "Epoch 12: avg_loss=0.5799\n",
      "Epoch 13: avg_loss=0.5774\n",
      "Epoch 14: avg_loss=0.5736\n",
      "Epoch 15: avg_loss=0.5719\n",
      "Epoch 16: avg_loss=0.5682\n",
      "Epoch 17: avg_loss=0.5658\n",
      "Epoch 18: avg_loss=0.5681\n",
      "Epoch 19: avg_loss=0.5686\n",
      "Epoch 20: avg_loss=0.5610\n",
      "Epoch 21: avg_loss=0.5551\n",
      "Epoch 22: avg_loss=0.5509\n",
      "Epoch 23: avg_loss=0.5469\n",
      "Epoch 24: avg_loss=0.5411\n",
      "Epoch 25: avg_loss=0.5401\n",
      "Epoch 26: avg_loss=0.5309\n",
      "Epoch 27: avg_loss=0.5263\n",
      "Epoch 28: avg_loss=0.5219\n",
      "Epoch 29: avg_loss=0.5181\n",
      "Epoch 30: avg_loss=0.5119\n",
      "Epoch 31: avg_loss=0.5044\n",
      "Epoch 32: avg_loss=0.4969\n",
      "Epoch 33: avg_loss=0.4902\n",
      "Epoch 34: avg_loss=0.4818\n",
      "Epoch 35: avg_loss=0.4727\n",
      "Epoch 36: avg_loss=0.4664\n",
      "Epoch 37: avg_loss=0.4553\n",
      "Epoch 38: avg_loss=0.4475\n",
      "Epoch 39: avg_loss=0.4344\n",
      "Epoch 40: avg_loss=0.4236\n",
      "Epoch 41: avg_loss=0.4168\n",
      "Epoch 42: avg_loss=0.4087\n",
      "Epoch 43: avg_loss=0.3993\n",
      "Epoch 44: avg_loss=0.3905\n",
      "Epoch 45: avg_loss=0.3794\n",
      "Epoch 46: avg_loss=0.3712\n",
      "Epoch 47: avg_loss=0.3651\n",
      "Epoch 48: avg_loss=0.3594\n",
      "Epoch 49: avg_loss=0.3512\n",
      "Epoch 50: avg_loss=0.3424\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# II. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨è¨­å®š\n",
    "# ---------------------------------------------------------------------------\n",
    "# Dataset ã‚¯ãƒ©ã‚¹ã¯ãã®ã¾ã¾ä½¿ç”¨ (paired_transform å¼•æ•°ã¯ä¸è¦)\n",
    "\n",
    "# Transform ã®ä¿®æ­£: Resize ã‚’ 256x256 ã«å¤‰æ›´\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), # â˜… 128x128 ã‹ã‚‰ 256x256 ã«å¤‰æ›´ â˜…\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = SketchDataset(\"dataset/train/rough\", \"dataset/train/line\", transform)\n",
    "\n",
    "# DataLoader: è§£åƒåº¦ã‚¢ãƒƒãƒ—ã«ä¼´ã„ã€VRAMç¯€ç´„ã®ãŸã‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ 2 ã«ä¸‹ã’ã‚‹ã“ã¨ã‚’æ¨å¥¨\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True) \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = UNetGenerator(in_channels=1, out_channels=1).to(device)\n",
    "\n",
    "\n",
    "pos_weight_value = 3.0 \n",
    "pos_weight_tensor = torch.tensor(pos_weight_value, dtype=torch.float).to(device)\n",
    "\n",
    "# 2. criterion ã« Tensor å‹ã® pos_weight ã‚’æ¸¡ã™\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
    "# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: å­¦ç¿’ç‡ã‚’ 0.0001 ã«ä¸‹ã’ã‚‹ (æš´èµ°é˜²æ­¢)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) \n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# III. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—\n",
    "# ---------------------------------------------------------------------------\n",
    "for epoch in range(50):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    model.train() \n",
    "    \n",
    "    for rough, line in loader:\n",
    "        rough, line = rough.to(device), line.to(device)\n",
    "\n",
    "        line = 1.0 - line\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(rough)\n",
    "    \n",
    "        # 1. ãƒ¡ã‚¤ãƒ³æå¤± (BCE with pos_weight)\n",
    "        loss_main_bce = criterion(pred, line)\n",
    "    \n",
    "        # 2. L1æå¤± (Sigmoidå¾Œã®å‡ºåŠ›ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®çµ¶å¯¾èª¤å·®)\n",
    "        # L1æå¤±ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ãƒ”ã‚¯ã‚»ãƒ«å€¤ãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«è¿‘ã¥ãã‚ˆã†ã«å¼·åˆ¶ã™ã‚‹ã€‚\n",
    "        loss_main_l1 = F.l1_loss(torch.sigmoid(pred), line) \n",
    "    \n",
    "        # 3. ãƒ¡ã‚¤ãƒ³æå¤±ã®çµ„ã¿åˆã‚ã›ã¨ã‚¨ãƒƒã‚¸æå¤±\n",
    "        # BCEã¨L1ã‚’ãƒŸãƒƒã‚¯ã‚¹ (ä¾‹: 80% BCE, 20% L1)\n",
    "        loss_main = 0.8 * loss_main_bce + 0.2 * loss_main_l1 \n",
    "    \n",
    "        loss_edge = edge_loss(torch.sigmoid(pred), line) \n",
    "\n",
    "        # ç·æå¤± (L1æå¤±ãŒå¤ªã•ã‚’æŠ‘åˆ¶ã™ã‚‹åŠ©ã‘ã«ãªã‚‹ãŸã‚ã€ã‚¨ãƒƒã‚¸é‡ã¿ã¯ 1.0 ã§ç¶­æŒã—ã¦ã‚‚ã‚ˆã„)\n",
    "        loss = loss_main + 1.0 * loss_edge\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ãƒ­ã‚°æ”¹å–„\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}: avg_loss={avg_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"checkpoints/unet_1ch_epoch{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71abc65b-8245-48de-8a2c-178e23f6c5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "# ... (UNetGeneratorã®å®šç¾©ãŒå¿…è¦) ...\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = UNetGenerator(in_channels=1, out_channels=1).to(device)\n",
    "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰...\n",
    "model.load_state_dict(torch.load(\"checkpoints/unet_1ch_epoch50.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "img = Image.open(\"test/rough/sample.jpg\").convert(\"L\")\n",
    "\n",
    "# â˜…â˜…â˜… ãƒªã‚µã‚¤ã‚ºè§£åƒåº¦ã‚’ 256x256 ã«å¤‰æ›´ â˜…â˜…â˜…\n",
    "img = TF.resize(img, (256, 256)) \n",
    "# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
    "\n",
    "img = TF.to_tensor(img).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = torch.sigmoid(model(img))  # 0ã€œ1\n",
    "\n",
    "out = 1.0 - out \n",
    "\n",
    "out = out.clamp(0,1)\n",
    "out_img = TF.to_pil_image(out[0].cpu())\n",
    "out_img.save(\"results/plan2.png\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890dab9-fb7f-497d-a3a0-4ff0551fac16",
   "metadata": {},
   "source": [
    "result\n",
    "![result](./results/plan1.png)1\n",
    "![result](./results/plan2.png)2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2721061-310d-4cb1-ab55-c83b623e9196",
   "metadata": {},
   "source": [
    "sample  \n",
    "![sample](./test/rough/sample.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091a4a7-931d-49c7-8818-a96e615d5396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
